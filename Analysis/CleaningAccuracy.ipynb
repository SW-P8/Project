{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from math import floor\n",
    "import DTC.json_read_write as json_read_write\n",
    "import pickle\n",
    "with open(\"./pc.pickle\", \"rb\") as fh:\n",
    "    pointcloud = pickle.load(fh)#json_read_write.read_point_cloud_from_json(\"AllcityPC.json\")\n",
    "    fh.close()\n",
    "print(\"pickle done\")\n",
    "safe_areas = json_read_write.read_safe_areas_from_json(\"AllcitySA10.json\")\n",
    "initialization_point = (116.20287663548845, 39.75112986803514)\n",
    "avg = 0\n",
    "maximum = 0\n",
    "i = 0\n",
    "list_of_points = []\n",
    "for k, v in safe_areas.items():\n",
    "    list_of_points.append(copy.copy(v.radius))\n",
    "    maximum = max(maximum, v.radius)\n",
    "    avg += v.radius\n",
    "    if v.radius > 14:\n",
    "        v.radius = 14\n",
    "    i += 1\n",
    "print((avg/i),  \"avg\", \"max\", maximum)\n",
    "list_of_points.sort()\n",
    "print(\"25% \", list_of_points[floor(((len(list_of_points)) * 0.25))])\n",
    "print(\"50% \", list_of_points[floor(((len(list_of_points)) * 0.50))])\n",
    "print(\"75% \", list_of_points[floor(((len(list_of_points)) * 0.75))])\n",
    "name = \"SA10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We use random.sample to get a random set of trajectories every time this runs***\n",
    "- furthermore, we take 5% of the points and shift them between 1-200m randomly with a random bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from DTC.noise_correction import NoiseCorrection\n",
    "point_cloud = pointcloud\n",
    "randomly_elected_trajectories = random.sample(point_cloud.trajectories, 1467)\n",
    "noise_corrector = NoiseCorrection(safe_areas, initialization_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_cleaned = 0\n",
    "total_points = 0\n",
    "for trajectory in randomly_elected_trajectories:\n",
    "    if len(trajectory.points) == 0:\n",
    "        continue\n",
    "    labels_of_cleaned_points = noise_corrector.noise_detection(trajectory)\n",
    "    points_cleaned += len(labels_of_cleaned_points)\n",
    "    total_points += len(trajectory.points)\n",
    "print(\"Points in randomly elected trajectories: \", total_points)\n",
    "print(\"Points cleaned: \", points_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 5% of 52489 - or 5 % of all the points in the collective pointcloud for all trajectories\n",
    "from math import ceil\n",
    "amount_to_shift = ceil(total_points * 0.05)\n",
    "print(\"Amount of points to shift: \", amount_to_shift)\n",
    "\n",
    "list_of_points_in_randomly_elected_trajectories = []\n",
    "for trajectory in randomly_elected_trajectories:\n",
    "    list_of_points_in_randomly_elected_trajectories.extend(trajectory.points)\n",
    "\n",
    "points_to_shift = random.sample(list_of_points_in_randomly_elected_trajectories, amount_to_shift)\n",
    "print(\"Amount of points actually shifted: \", len(points_to_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTC.distance_calculator import DistanceCalculator\n",
    "for point in points_to_shift:\n",
    "    point.set_coordinates(DistanceCalculator.shift_point_with_bearing(point, random.randint(1,200), random.randint(0,359)))\n",
    "    point.noise = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean trajectories following shifting. \n",
    "After Cleaning, make comparison with the old trajectory points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_of_cleaned_points = []\n",
    "for trajectory in randomly_elected_trajectories:\n",
    "    if len(trajectory.points) == 0:\n",
    "        continue\n",
    "    labels_of_locally_cleaned_points = noise_corrector.noise_detection(trajectory)\n",
    "    labels_of_cleaned_points.extend(labels_of_locally_cleaned_points)\n",
    "\n",
    "amount_of_cleaned_points = 0\n",
    "amount_of_noisy_points_cleaned = 0\n",
    "for label in labels_of_cleaned_points:\n",
    "    amount_of_cleaned_points += 1\n",
    "    if label == True:\n",
    "        amount_of_noisy_points_cleaned += 1\n",
    "\n",
    "cleaned = (\"Amount of cleaned points: \", amount_of_cleaned_points)\n",
    "noisy_points_cleaned = (\"Amount of noisy points cleaned: \", amount_of_noisy_points_cleaned)\n",
    "not_noisy_cleaned = (\"Amount of not noisy points cleaned: \", amount_of_cleaned_points - amount_of_noisy_points_cleaned)\n",
    "noisy_not_cleaned = (\"Amount of noisy points not cleaned: \", amount_to_shift - amount_of_noisy_points_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy, precision and recall\n",
    "\n",
    "def precision(tp, fp):\n",
    "    return(tp/(tp+fp))\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return(tp/(tp+fn))\n",
    "    \n",
    "def accuracy(tp, tn, fp, fn ):\n",
    "    return((tn+tp)/(tp+tn+fn+fp))\n",
    "\n",
    "#TOTAL - TP - FP - FN\n",
    "precision_ = (f\"Precision = {precision(amount_of_noisy_points_cleaned, (amount_of_cleaned_points - amount_of_noisy_points_cleaned))}\")\n",
    "recall_ = (f\"Recall = {recall(amount_of_noisy_points_cleaned, (amount_to_shift-amount_of_noisy_points_cleaned))}\")\n",
    "accuracy_ = (f\"\"\"Accuracy = {accuracy(amount_of_noisy_points_cleaned, (total_points - amount_of_noisy_points_cleaned - (amount_of_cleaned_points - amount_of_noisy_points_cleaned)\n",
    "      - (amount_to_shift-amount_of_noisy_points_cleaned)), (amount_of_cleaned_points - amount_of_noisy_points_cleaned), (amount_to_shift-amount_of_noisy_points_cleaned))}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output metrics to file\n",
    "output = f\"\"\"\n",
    "SA type {name} \\n\n",
    "total points {total_points} \\n\n",
    "points to shift {amount_to_shift} \\n\n",
    "points shifted {len(points_to_shift)} \\n\n",
    "points cleaned {cleaned} \\n\n",
    "not noisy points cleaned {not_noisy_cleaned} \\n \n",
    "noisy points cleaned {noisy_points_cleaned} \\n\n",
    "noisy points not cleaned {noisy_not_cleaned} \\n \n",
    "Metrics: \\n\n",
    "Precision {precision_} \\n\n",
    "Recall {recall_} \\n\n",
    "Accuracy {accuracy_} \\n\n",
    "\"\"\"\n",
    "\n",
    "with open(\"./Test_results.txt\", \"a\") as fh:\n",
    "    fh.write(output)\n",
    "    fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
