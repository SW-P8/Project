{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTC.dtc_executor import DTCExecutor\n",
    "from DTC.route_skeleton import RouteSkeleton\n",
    "import json\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#a = DTCExecutor()\n",
    "#pc = a.create_point_cloud_with_n_points(17000000, city=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./pc.pickle', 'wb') as handle:\n",
    "#    pickle.dump(pc, file=handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = None \n",
    "with open('./pc.pickle', 'rb') as handle:\n",
    "    pc = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTC.gridsystem import GridSystem\n",
    "from DTC.construct_safe_area import SafeArea\n",
    "gs = GridSystem(pc)\n",
    "avg = 0\n",
    "iterations = 0\n",
    "max_radius = 0\n",
    "median = []\n",
    "converted_data = {}\n",
    "anchor = 0\n",
    "with open(\"./AllcitySA(1).json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    for key, value in data.items():\n",
    "        max_radius = max(max_radius, value[0])\n",
    "        median.append(value[0])\n",
    "        iterations += 1 \n",
    "        \n",
    "        clean_key = key.strip('()').split(',')\n",
    "        tuple_key = tuple(float(num.strip()) for num in clean_key)\n",
    "        if value[0] > 50:\n",
    "            value[0] = 50\n",
    "            anchor = tuple_key\n",
    "        avg += value[0]\n",
    "        converted_data[tuple_key] = SafeArea(tuple_key, radius=value[0], cardinality=value[1], confidence_change=1, normalisation_factor=0.5, cardinality_squish=0.15, max_confidence_change=0.15)\n",
    "median.sort()\n",
    "print(median[ceil(len(median)/2)], \"     \", anchor)\n",
    "print(avg/iterations, \"maximum radius\", max_radius)\n",
    "gs.safe_areas = converted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Loading SafeAreas and Checking AVG radius of SAs***\n",
    "- Atm our radius is 33.3 cells, which is 167 meters - this is too much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "print(len(gs.pc.trajectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract r\n",
    "import random\n",
    "from DTC.clean import CleanTraj\n",
    "traj_for_test = random.sample(gs.pc.trajectories, 1467)\n",
    "clean = CleanTraj(gs.safe_areas, gs.initialization_point, pc.min_latitude, pc.min_longitude)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for traj in traj_for_test:\n",
    "    traj, c = clean.clean(traj=traj)\n",
    "    a += len(c)\n",
    "print(a)\n",
    "l = 0\n",
    "for t in traj_for_test:\n",
    "    l += len(t.points)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 5% of 52489 - or 5 % of all the points in the collective pointcloud for all trajectories\n",
    "from math import ceil\n",
    "amount_to_shift = ceil(l * 0.05)\n",
    "print(amount_to_shift, \" and \", l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We use random.sample to get a random set of trajectories every time this runs***\n",
    "- furthermore, we take 5% of the points and shift them between 1-200m randomly with a random bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTC.distance_calculator import DistanceCalculator\n",
    "list_of_points = []\n",
    "for traj in traj_for_test:\n",
    "    for point in traj.points:\n",
    "        list_of_points.append(point)\n",
    "\n",
    "points_to_shift = random.sample(list_of_points, amount_to_shift)\n",
    "print(len(points_to_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTC.distance_calculator import DistanceCalculator\n",
    "from DTC.point import Point\n",
    "from datetime import datetime\n",
    "#Shifting the points twice seem to give me coordinate that does not work - this does not really make any sense\n",
    "\n",
    "for point in points_to_shift:\n",
    "    print(point.longitude)\n",
    "    point_shifted = DistanceCalculator.shift_point_with_bearing(point, random.randint(1,200), random.randint(0,359))\n",
    "    point.longitude = point_shifted[0]\n",
    "    point.latitude = point_shifted[1]\n",
    "    point.noise = True\n",
    "    point = DistanceCalculator.shift_point_with_bearing(point, random.randint(1,200), DistanceCalculator.EAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTC import clean\n",
    "clean_t = clean.CleanTraj(gs.safe_areas, gs.initialization_point, pc.min_latitude, pc.min_longitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_points = []\n",
    "for traj in traj_for_test:\n",
    "    traj, a = clean_t.clean(traj=traj)\n",
    "    cleaned_points.extend(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After Cleaning, make comparison with the old trajectory points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cleaned_points))\n",
    "i = 0\n",
    "a = 0\n",
    "for point in cleaned_points:\n",
    "    a += 1\n",
    "    if point == True:\n",
    "        i += 1\n",
    "print(a, \" \" , i)\n",
    "i = 0\n",
    "for point in list_of_points:\n",
    "    if point.noise == True:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Setup**\n",
    "\n",
    "- Using the setup from the paper DTC\n",
    "- Using 1472 trajectories as in the paper in the first set of experiments\n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "**This is only with a MR with 2million points**\n",
    "\n",
    "*first run*\n",
    "- 926 cleaned\n",
    "- 3107 to clean\n",
    "\n",
    "*second run*\n",
    "- 1140 cleaned\n",
    "- 2564 to clean\n",
    "\n",
    "\n",
    "**Running with 11 million points**\n",
    "\n",
    "*first run*\n",
    "- 739 cleaned\n",
    "- 2573 to clean\n",
    "\n",
    "*second run*\n",
    "- 775 cleaned\n",
    "- 2342 to clean\n",
    "\n",
    "*third run*\n",
    "- 850 cleaned\n",
    "- 2394 to clean\n",
    "\n",
    "*fourth run*\n",
    "- 656 cleaned\n",
    "- 2386 to clean\n",
    "\n",
    "*fifth run*\n",
    "- 1137 cleaned\n",
    "- 3998 to clean\n",
    "\n",
    "- VERY low amount of true positives - thats bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cleaned = sum([739, 775, 850, 656]) / sum([2573, 2342, 2394, 2386])\n",
    "print(average_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "\n",
    "def setup_grid_to_geo_transformer(origin_latitude, origin_longitude):\n",
    "    # Create a Proj instance for the local grid system. This could be UTM or any other fitting your local context.\n",
    "    # Here, I'm using a simple Transverse Mercator projection centered on the origin with a specific false easting and northing.\n",
    "    grid_proj = Proj(proj='tmerc', lat_0=origin_latitude, lon_0=origin_longitude, k=1, x_0=0, y_0=0, ellps='WGS84', units='m')\n",
    "\n",
    "    # WGS84 Proj instance for lat/long\n",
    "    geo_proj = Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "    return grid_proj, geo_proj\n",
    "\n",
    "def convert_grid_to_geo(x, y, grid_proj, geo_proj):\n",
    "    # Transform from grid coordinates to geographic coordinates\n",
    "    lon, lat = transform(grid_proj, geo_proj, x, y)\n",
    "    return lat, lon\n",
    "\n",
    "# Example usage\n",
    "origin_latitude = 39.915  # Adjust to your grid's origin latitude\n",
    "origin_longitude = 116.404  # Adjust to your grid's origin longitude\n",
    "grid_proj, geo_proj = setup_grid_to_geo_transformer(origin_latitude, origin_longitude)\n",
    "\n",
    "# Example grid coordinates\n",
    "x, y = 100, 200  # These should be in meters if your grid system uses meters\n",
    "lat, lon = convert_grid_to_geo(x, y, grid_proj, geo_proj)\n",
    "print(f\"Latitude: {lat}, Longitude: {lon}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
