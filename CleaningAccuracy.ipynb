{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DTC.json_read_write as json_read_write\n",
    "point_cloud = json_read_write.read_point_cloud_from_json(\"AllcityPC.json\")\n",
    "safe_areas = json_read_write.read_safe_areas_from_json(\"AllcitySA.json\")\n",
    "initialization_point = (116.20287663548845, 39.75112986803514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from DTC.noise_correction import NoiseCorrection\n",
    "randomly_elected_trajectories = random.sample(point_cloud.trajectories, 1467)\n",
    "noise_corrector = NoiseCorrection(safe_areas, initialization_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in randomly elected trajectories:  49138\n",
      "Points cleaned:  463\n"
     ]
    }
   ],
   "source": [
    "points_cleaned = 0\n",
    "total_points = 0\n",
    "for trajectory in randomly_elected_trajectories:\n",
    "    _, labels_of_cleaned_points = noise_corrector.noise_detection(trajectory)\n",
    "    points_cleaned += len(labels_of_cleaned_points)\n",
    "    total_points += len(trajectory.points)\n",
    "print(\"Points in randomly elected trajectories: \", total_points)\n",
    "print(\"Points cleaned: \", points_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of points to shift:  2457\n",
      "Amount of points actually shifted:  2457\n"
     ]
    }
   ],
   "source": [
    "# use 5% of 52489 - or 5 % of all the points in the collective pointcloud for all trajectories\n",
    "from math import ceil\n",
    "amount_to_shift = ceil(total_points * 0.05)\n",
    "print(\"Amount of points to shift: \", amount_to_shift)\n",
    "\n",
    "list_of_points_in_randomly_elected_trajectories = []\n",
    "for trajectory in randomly_elected_trajectories:\n",
    "    list_of_points_in_randomly_elected_trajectories.extend(trajectory.points)\n",
    "\n",
    "points_to_shift = random.sample(list_of_points_in_randomly_elected_trajectories, amount_to_shift)\n",
    "print(\"Amount of points actually shifted: \", len(points_to_shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We use random.sample to get a random set of trajectories every time this runs***\n",
    "- furthermore, we take 5% of the points and shift them between 1-200m randomly with a random bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTC.distance_calculator import DistanceCalculator\n",
    "for point in points_to_shift:\n",
    "    point.set_coordinates(DistanceCalculator.shift_point_with_bearing(point, random.randint(1,200), random.randint(0,359)))\n",
    "    point.noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n",
      "Amount of cleaned points:  243\n",
      "Amount of noisy points cleaned:  176\n",
      "Amount of noisy points not cleaned:  2281\n"
     ]
    }
   ],
   "source": [
    "labels_of_cleaned_points = []\n",
    "for trajectory in randomly_elected_trajectories:\n",
    "    _, labels_of_locally_cleaned_points = noise_corrector.noise_detection(trajectory)\n",
    "    labels_of_cleaned_points.extend(labels_of_locally_cleaned_points)\n",
    "amount_of_cleaned_points = 0\n",
    "amount_of_noisy_points_cleaned = 0\n",
    "for label in labels_of_cleaned_points:\n",
    "    amount_of_cleaned_points += 1\n",
    "    if label == True:\n",
    "        amount_of_noisy_points_cleaned += 1\n",
    "print(\"Amount of cleaned points: \", amount_of_cleaned_points)\n",
    "print(\"Amount of noisy points cleaned: \", amount_of_noisy_points_cleaned)\n",
    "print(\"Amount of not noisy points cleaned: \", )\n",
    "print(\"Amount of noisy points not cleaned: \", amount_to_shift - amount_of_noisy_points_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After Cleaning, make comparison with the old trajectory points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Setup**\n",
    "\n",
    "- Using the setup from the paper DTC\n",
    "- Using 1472 trajectories as in the paper in the first set of experiments\n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "**This is only with a MR with 2million points**\n",
    "\n",
    "*first run*\n",
    "- 926 cleaned\n",
    "- 3107 to clean\n",
    "\n",
    "*second run*\n",
    "- 1140 cleaned\n",
    "- 2564 to clean\n",
    "\n",
    "\n",
    "**Running with 11 million points**\n",
    "\n",
    "*first run*\n",
    "- 739 cleaned\n",
    "- 2573 to clean\n",
    "\n",
    "*second run*\n",
    "- 775 cleaned\n",
    "- 2342 to clean\n",
    "\n",
    "*third run*\n",
    "- 850 cleaned\n",
    "- 2394 to clean\n",
    "\n",
    "*fourth run*\n",
    "- 656 cleaned\n",
    "- 2386 to clean\n",
    "\n",
    "*fifth run*\n",
    "- 1137 cleaned\n",
    "- 3998 to clean\n",
    "\n",
    "- VERY low amount of true positives - thats bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cleaned = sum([739, 775, 850, 656]) / sum([2573, 2342, 2394, 2386])\n",
    "print(average_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "\n",
    "def setup_grid_to_geo_transformer(origin_latitude, origin_longitude):\n",
    "    # Create a Proj instance for the local grid system. This could be UTM or any other fitting your local context.\n",
    "    # Here, I'm using a simple Transverse Mercator projection centered on the origin with a specific false easting and northing.\n",
    "    grid_proj = Proj(proj='tmerc', lat_0=origin_latitude, lon_0=origin_longitude, k=1, x_0=0, y_0=0, ellps='WGS84', units='m')\n",
    "\n",
    "    # WGS84 Proj instance for lat/long\n",
    "    geo_proj = Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "    return grid_proj, geo_proj\n",
    "\n",
    "def convert_grid_to_geo(x, y, grid_proj, geo_proj):\n",
    "    # Transform from grid coordinates to geographic coordinates\n",
    "    lon, lat = transform(grid_proj, geo_proj, x, y)\n",
    "    return lat, lon\n",
    "\n",
    "# Example usage\n",
    "origin_latitude = 39.915  # Adjust to your grid's origin latitude\n",
    "origin_longitude = 116.404  # Adjust to your grid's origin longitude\n",
    "grid_proj, geo_proj = setup_grid_to_geo_transformer(origin_latitude, origin_longitude)\n",
    "\n",
    "# Example grid coordinates\n",
    "x, y = 100, 200  # These should be in meters if your grid system uses meters\n",
    "lat, lon = convert_grid_to_geo(x, y, grid_proj, geo_proj)\n",
    "print(f\"Latitude: {lat}, Longitude: {lon}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
